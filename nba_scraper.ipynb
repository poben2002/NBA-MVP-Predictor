{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1977,\n",
       " 1978,\n",
       " 1979,\n",
       " 1980,\n",
       " 1981,\n",
       " 1982,\n",
       " 1983,\n",
       " 1984,\n",
       " 1985,\n",
       " 1986,\n",
       " 1987,\n",
       " 1988,\n",
       " 1989,\n",
       " 1990,\n",
       " 1991,\n",
       " 1992,\n",
       " 1993,\n",
       " 1994,\n",
       " 1995,\n",
       " 1996,\n",
       " 1997,\n",
       " 1998,\n",
       " 1999,\n",
       " 2000,\n",
       " 2001,\n",
       " 2002,\n",
       " 2003,\n",
       " 2004,\n",
       " 2005,\n",
       " 2006,\n",
       " 2007,\n",
       " 2008,\n",
       " 2009,\n",
       " 2010,\n",
       " 2011,\n",
       " 2012,\n",
       " 2013,\n",
       " 2014,\n",
       " 2015,\n",
       " 2016,\n",
       " 2017,\n",
       " 2018,\n",
       " 2019,\n",
       " 2020,\n",
       " 2021,\n",
       " 2022]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = list(range(1977, 2023))\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_start = \"https://www.basketball-reference.com/awards/awards_{}.html\"\n",
    "\n",
    "if not os.path.exists(\"nbamvp2\"):\n",
    "    os.makedirs(\"nbamvp2\")\n",
    "\n",
    "for year in years:\n",
    "    url = url_start.format(year)\n",
    "\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"nbamvp2/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 166107: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benja\\Documents\\Projs\\nbamvp\\nba_scraper.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benja/Documents/Projs/nbamvp/nba_scraper.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnbamvp2/1977.html\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/benja/Documents/Projs/nbamvp/nba_scraper.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     page \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[1;32mc:\\Users\\benja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[39mreturn\u001b[39;00m codecs\u001b[39m.\u001b[39mcharmap_decode(\u001b[39minput\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors,decoding_table)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 166107: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "with open(\"nbamvp2/1977.html\") as f:\n",
    "    page = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('tr', class_=\"over_header\").decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_table = soup.find(id=\"mvp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvp_1977 = pd.read_html(str(mvp_table))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"mvp/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"over_header\").decompose()\n",
    "    mvp_table = soup.find(id=\"mvp\")\n",
    "    mvp = pd.read_html(str(mvp_table))[0]\n",
    "    mvp[\"Year\"] = year\n",
    "\n",
    "    dfs.append(mvp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\"\n",
    "url = player_stats_url.format(1977)\n",
    "data = requests.get(url)\n",
    "with open(\"player/1991.html\", \"w+\") as f:\n",
    "    f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome(executable_path=\"/Users/vik/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "year = 1977\n",
    "url = player_stats_url.format(year)\n",
    "driver.get(url)\n",
    "driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "time.sleep(2)\n",
    "\n",
    "html = driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"player/{}.html\".format(year), \"w+\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = player_stats_url.format(year)\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"player/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    with open(\"player/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    player_table = soup.find(id=\"per_game_stats\")\n",
    "    player = pd.read_html(str(player_table))[0]\n",
    "    player[\"Year\"] = year\n",
    "    dfs.append(player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "players = pd.concat(dfs)\n",
    "players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "players.to_csv(\"players_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_url = \"https://www.basketball-reference.com/leagues/NBA_{}_standings.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years\n",
    "    url = team_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "    with open(\"team/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"team/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    team_table = soup.find(id=\"divs_standings_E\")\n",
    "    team = pd.read_html(str(player_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Eastern Conference\"]\n",
    "    del team[\"Eastern Conference\"]\n",
    "    dfs.append(team)\n",
    "\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    soup.find('tr', class_=\"thead\").decompose()\n",
    "    team_table = soup.find(id=\"divs_standings_W\")\n",
    "    team = pd.read_html(str(team_table))[0]\n",
    "    team[\"Year\"] = year\n",
    "    team[\"Team\"] = team[\"Western Conference\"]\n",
    "    del team[\"Western Conference\"]\n",
    "    dfs.append(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(dfs)\n",
    "teams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
